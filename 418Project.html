<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>418 Final Project</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="aboutme.html">About Me</a></li>
							<li><a href="https://www.gamecreation.org/members/WoodyMcCoy">GCS Page</a></li>
							<li><a href="https://github.com/Woodmanan">Github</a></li>
							<li><a href="https://mwmccoy.itch.io/">Itch.io</a></li>
							<!--<li><a href="elements.html">Elements</a></li>-->
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h3>Summary</h3>
							<p>Creating bounding volume hierarchies for triangle meshes in parallel on multi-core CPU platforms.</p>
							<h3>Background</h3>
							<ul>
									<li> Creating a bounding volume hierarchy is often quite an expensive process for arbitrarily complex meshes. It is in essence a process of hierarchically sorting the scene primitives into spatially local groups. </li>
									<li> The serial algorithm involves iteratively dividing the set of scene primitives, where the best division is dependent on a cost function known as the surface area heuristic (SAH). The end product is a binary tree, where nodes represent a bounding box surrounding all scene primitives contained in the leaves of the subtree with the current node as its root. While leaf nodes represent a list of scene primitives. </li>
									<li> The process of creating a BVH can be split into many sub problems. Viewing each node of the BVH tree as a sub problem already puts into view the potential for parallelism. </li>
									<li> Since sequential creation of BVHs can be expensive, it involves at least O(nlogn) since sorting can be reduced to the problem of BVH creation (at least when the BVH can have arbitrary depth and leaf nodes contain only one primitive). Therefore a lot of room is left for improvement when parallelizing this process. </li>
								</ul>



							<h3>The Challenge</h3>
							<ul>
								<li> As mentioned above, the process of creating a BVH can be separated into sub-problems, where each sub-problem is represented by a node in the BVH tree. These sub problems depend on their parent node sub problem to be finished before the current one can start. So the task tree is a DAG where parent nodes point to their corresponding child nodes. These are the dependencies that we must take care of to correctly parallelise the algorithm. </li>
									
								<li> Another problem is the issue of quality. Similar to the problem in Assignment 4, we can use techniques that sacrifice the quality of the final BVH but provide considerable speedups to the algorithm. These sacrifices can also lead to more room for parallelism. We can evaluate the quality of the final BVH either using the SAH, or time needed to render a specific scene using the BVH. </li>
							</ul>

							<h3>Resources</h3>
							<ul>
								<li> We will be using the 15-462 code for ray-tracing and scene manipulations as starter code for our project. We are using this due to the rich set of visualization capabilities in Scotty3D, which will allow us to present and evaluate our work with greater ease. </li>
									
								<li> We are also looking into the paper "Parallel BVH Construction using k-means Clustering" from the authors Daniel Meister and Jiri Bittner. We plan on visiting their approach and seeing how this approximate method using k-means will lead to more speed ups. </li>
							</ul>

							<h3>Goals and Deliverables - Plan to achieve</h3>
							<ul>
								<li> Implement a fully functional parallel BVH creation pipeline that can be used for ray-tracing in Scotty3D </li>
								<li> Provide speed-up graphs for BVH creation on multi-core CPU platforms </li>
								<li> Provide speed-up graphs relative to BVH quality - BVH quality can be measured by SAH or rendering speeds </li>
							</ul>

							<h3>Goals and Deliverables - Hope to achieve</h3>
							<ul>
								<li> Implement parallelism using k-means, which involves parallelizing the k-means algorithm </li>
							</ul>

							<h3>Platform Choice </h3>
							<ul>
								<li> Written in C++ with message passing using OpenMP </li>
							</ul>

							<h3>Schedule</h3>
							<table class="alt">
										<thead>
											<tr>
												<th>Week</th>
												<th>Goals</th>
											</tr>
										</thead>
										<tbody>
											<tr>
												<td>Week 1</td>
												<td>
Revisit Scotty3D code and familiarize ourselves with how BVH creation works and plan out how our parallelization strategy will work
												</td>
											</tr>
											<tr>
												<td>Week 2</td>
												<td>
Implement parallelism for basic BVH creation for arbitrarily large scenes

												</td>
											</tr>
											<tr>
												<td>Week 3</td>
												<td>
Evaluate parallel algorithm in terms of BVH quality and speed-up achieved
												</td>
											</tr>
											<tr>
												<td>Week 4</td>
												<td>
Project checkpoint - Investigate other methods for BVH creation speed-up, e.g. k-means method
												</td>
											</tr>
											<tr>
												<td>Week 5</td>
												<td>
Implement new methods, e.g. k-means method and evaluate their performance with regards to speed-up and quality of BVH
												</td>
											</tr>
											<tr>
												<td>Week 6</td>
												<td>Handin and Demo</td>
											</tr>

										</tbody>
							</table>






							
						</div>
					</div>


					<div id="main">
						<div class="inner">
							<h1>Milestone Report</h1>
							<h3>Updated Schedule</h3>
							<table class="alt">
								<thead>
									<tr>
										<th>Week</th>
										<th>Goals</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td>Week 1</td>
										<td>
Revisit Scotty3D code and familiarize ourselves with how BVH creation works and plan out how our parallelization strategy will work
										</td>
									</tr>
									<tr>
										<td>Week 2</td>
										<td>
Implement parallelism for basic BVH creation for arbitrarily large scenes

										</td>
									</tr>
									<tr>
										<td>Week 3</td>
										<td>
Debug parallel implementation for BVH creation. Currently using a task-queue implementation, but bugs are persistent within implementation preventing us from rigorously testing and benchmarking our approach.										</td>
									</tr>
									<tr>
										<td>Week 4.0</td>
										<td>
Ryan: Debug current task-queue based implementation method. Concurrency errors occur in the process of establishing a work queue with a single lock.										
Manan: Investigate other methods for BVH creation speed-up, e.g. k-means method		</td>						</tr>
									<tr>
										<td>Week 4.5</td>
										<td>
											Ryan: Carry out benchmarks for task-queue approach. Benchmarks should be on time only, theoretically, it shouldn’t affect BVH quality.
											Manan: Implement k-means approach for parallel BVH creation.											
										</td>
									</tr>
									<tr>
										<td>Week 5.0</td>
										<td>Manan and Ryan: Continue implementing new method using k-means
										</td>
									</tr>

									<tr>
										<td>Week 5.5</td>
										<td>Manan and Ryan: Evaluate and compare the differences between BVH construction using k-means and parallelization of sequential algorithm
										</td>
									</tr>

									<tr>
										<td>Week 6.0</td>
										<td>Manan: Prepare speed-up graphs. Ryan: Prepare BVH quality graphs
										</td>
									</tr>


								</tbody>
					</table>



							<h3>Work Completed So Far</h3>
							<ul>
								<li> So far, we have the serial version of the BVH formation working. We are currently working on implementing the parallel version on a shared address space model using OpenMP. The serial version of BVH creation works as follows. We begin with a list of all primitives of a particular scene, we then sort these primitives based on their mid-points, and search for a division of the scene that adheres to optimizing the surface-area heuristic (SAH). After the optimal division is found, we create two children nodes connecting to the root node, where each child node corresponds to one side of the split. The above process of splitting the scene primitives is repeated until we reach the termination condition of creating leaf nodes (usually a hard limit on the number of primitives are in a node). </li>
									
								<li> Our current approach uses a task-queue based approach. Since creation of nodes in a BVH depends on the completion of parent nodes, the dependence graph of the problem is a DAG that is the exact shape of the binary tree representing the BVH. There are a few characteristics about these “tasks”: earlier “tasks” have a higher cost, since they are optimizing over a larger number of primitives, and also tasks are dependent on parent tasks. With these two characteristics in mind, we decided that maintaining a task-queue is the most intuitive solution to this problem. Earlier tasks will spawn 2 tasks corresponding to their child nodes, and OpenMP threads will continuously pick up new threads until no work needs to be done anymore. We maintained access to the work-queue with a centralized lock. </li>
							</ul>

							<h3>Goals and Deliverables - Plan to achieve</h3>
							<ul>
								<li> Implement a fully functional parallel BVH creation pipeline that can be used for ray-tracing in Scotty3D </li>
								<li> Provide speed-up graphs for BVH creation on multi-core CPU platforms </li>
								<li> Provide speed-up graphs relative to BVH quality - BVH quality can be measured by SAH or rendering speeds </li>
							</ul>

							<h3>Goals and Deliverables - Hope to achieve</h3>
							<ul>
								<li> Implement parallelism using k-means, which involves parallelizing the k-means algorithm </li>
							</ul>

							<h3>Updated Goals and Deliverables</h3>
							<ul>
								<li>We believe that we can achieve all of the above, but decided on making one major change. We decided to move rendering scenes with the parallel created BVHs to the “nice to have” section as we believe that evaluating the performance of our algorithm using </li>
							</ul>
							<h3>Poster Session Deliverables</h3>
							<ul>
								<li> For our poster session, we are planning to show speedup graphs of implementations, showing the increases to speed that come from adding more cores. Additionally, we will present multiple of these graphs for the different methods we tried for BVH creation. While a demo would be possible, it would most likely be fairly uninteresting to watch in real time, so we will choose not to do that.</li>
							</ul>

							<h3>Issues and Concerns</h3>
							<ul>
								<li> None so far. We are a little behind schedule compared to our proposal, but we believe we can catch up to it over break.</li>
							</ul>
						</div>
					</div>


			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
